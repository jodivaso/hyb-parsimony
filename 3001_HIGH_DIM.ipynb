{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f087ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"MLPRegressor(activation='logistic', alpha=0.010729877296924203,\\n             hidden_layer_sizes=1, max_iter=5000, n_iter_no_change=20,\\n             random_state=1234, solver='lbfgs', tol=1e-05)\"],\n",
       "       [\"KernelRidge(alpha=0.3664462701238023, gamma=0.01808883688516421, kernel='rbf')\"],\n",
       "       ['SVR(C=0.8476135773996406, gamma=0.02324169209860404)'],\n",
       "       ['KNeighborsRegressor(n_neighbors=11)'],\n",
       "       ['Lasso(alpha=0.0002735058905983914)'],\n",
       "       ['Ridge(alpha=0.1321381563140431)'],\n",
       "       ['RandomForestRegressor(max_depth=17, min_samples_split=25, n_estimators=473)'],\n",
       "       ['DecisionTreeRegressor(max_depth=2, min_samples_split=20)']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mat = pd.read_csv('./res_models.csv')\n",
    "mat.iloc[:,6:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "649ca26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d1719f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['LogisticRegression(C=2.5457613022710692)'],\n",
       "       ['SVC(C=10.017400170851333, gamma=0.030271440833644657, probability=True)'],\n",
       "       [\"MLPClassifier(activation='logistic', alpha=0.08468913411920591,\\n              hidden_layer_sizes=8, max_iter=5000, n_iter_no_change=20,\\n              random_state=1234, solver='lbfgs', tol=1e-05)\"],\n",
       "       ['DecisionTreeClassifier(max_depth=2, min_samples_split=19)'],\n",
       "       ['RandomForestClassifier(max_depth=20, n_estimators=126)'],\n",
       "       ['KNeighborsClassifier(n_neighbors=7, p=1)']], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mat = pd.read_csv('./res_models_class.csv')\n",
    "mat.iloc[:,6:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af9dd135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85615/3558207623.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  mat.to_latex(index=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\\\begin{tabular}{rlrrrll}\\n\\\\toprule\\n Unnamed: 0 &                   algo &  Logloss\\\\_10R5CV &  Logloss\\\\_Test &  NFS &                                  selected\\\\_features &                                         best\\\\_model \\\\\\\\\\n\\\\midrule\\n          0 &     LogisticRegression &        0.066868 &      0.079512 &   10 & ['radius error' 'smoothness error' 'compactness... &           LogisticRegression(C=2.5457613022710692) \\\\\\\\\\n          2 &                    SVC &        0.061924 &      0.093283 &    9 & ['mean texture' 'radius error' 'smoothness erro... & SVC(C=10.017400170851333, gamma=0.0302714408336... \\\\\\\\\\n          1 &          MLPClassifier &        0.055662 &      0.100951 &   14 & ['mean smoothness' 'mean compactness' 'mean con... & MLPClassifier(activation='logistic', alpha=0.08... \\\\\\\\\\n          3 & DecisionTreeClassifier &        0.214163 &      0.304484 &    7 & ['mean radius' 'mean compactness' 'mean concave... & DecisionTreeClassifier(max\\\\_depth=2, min\\\\_samples... \\\\\\\\\\n          4 & RandomForestClassifier &        0.098342 &      0.422900 &   12 & ['mean texture' 'mean smoothness' 'mean concave... & RandomForestClassifier(max\\\\_depth=20, n\\\\_estimato... \\\\\\\\\\n          5 &   KNeighborsClassifier &        0.079658 &      0.714111 &   17 & ['mean radius' 'mean texture' 'mean smoothness'... &           KNeighborsClassifier(n\\\\_neighbors=7, p=1) \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.to_latex(index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e42b01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10) (442,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2adce046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T18:33:46.824478Z",
     "start_time": "2023-04-21T18:33:46.803049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1 1.5.3 1.23.5\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob, random, time, sys\n",
    "from string import printable\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import RepeatedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso, RidgeClassifier, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error, log_loss, accuracy_score, mean_absolute_error\n",
    "from sklearn.datasets import load_diabetes, load_iris\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from HYBparsimony import Population, HYBparsimony, order\n",
    "from HYBparsimony.hybparsimony import default_cv_score_classification\n",
    "from HYBparsimony.util import knn_complexity\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# from GAparsimony import GAparsimony, Population, getFitness\n",
    "# from GAparsimony.util import linearModels_complexity, svm_complexity, mlp_complexity, randomForest_complexity\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# from PSOparsimony_Nested import PSOparsimony\n",
    "from bayes_opt import BayesianOptimization\n",
    "# from HYBparsimony import HYBparsimony\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# from Hyb_nestedCV import HYB_NestedCV\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# comment in Beronia (not installed)\n",
    "# from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "print(sklearn.__version__, pd.__version__, np.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8905501",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fdb526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:11:51.498235Z",
     "start_time": "2023-04-12T14:11:51.419202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_HYB_database_boston_norm_csv_algorithm_kridge_GPU_False_nump_15_maxiter_200_early_35_pcrossover_elitists_None_pcrossover_0_1_Lambda_1_0_c1_1_193_c2_1_193_IWmax_0_9_IWmin_0_4_K_3_globthr_1_0_CVrep_5_CVspl_5_nruns_5_numseeds_5_timelimitmin_1_rerank_0_001_dirout_hyb_1001_12abr23_e27_not_muted_3_n_jobs_1_n_jobs_autogluon_64_temp_autogluon_temp_autogluon_train_size_2000\n",
      "Using GPU= NO\n"
     ]
    }
   ],
   "source": [
    "# Argumentos\n",
    "# ----------\n",
    "def in_nb():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--method\", type=str, default=\"PSO\")\n",
    "parser.add_argument(\"--database\", type=str, default=\"boston_norm.csv\")\n",
    "parser.add_argument(\"--algorithm\", type=str, default=\"\")  # kridge, mlp, rf, svr\n",
    "parser.add_argument(\"--GPU\", type=str, default=\"False\")\n",
    "parser.add_argument(\"--nump\", type=int, default=40)\n",
    "parser.add_argument(\"--maxiter\", type=int, default=200)\n",
    "parser.add_argument(\"--early\", type=int, default=35)\n",
    "parser.add_argument(\"--pcrossover_elitists\", type=float, default=None)\n",
    "parser.add_argument(\"--pcrossover\", type=float, default=None)\n",
    "parser.add_argument(\"--Lambda\", type=float, default=1.0)\n",
    "parser.add_argument(\"--c1\", type=float, default=1.193)\n",
    "parser.add_argument(\"--c2\", type=float, default=1.193)\n",
    "parser.add_argument(\"--IWmax\", type=float, default=0.9)\n",
    "parser.add_argument(\"--IWmin\", type=float, default=0.4)\n",
    "parser.add_argument(\"--K\", type=int, default=3)\n",
    "parser.add_argument(\"--globthr\", type=float, default=1.0)\n",
    "parser.add_argument(\"--CVrep\", type=int, default=5)\n",
    "parser.add_argument(\"--CVspl\", type=int, default=5)\n",
    "parser.add_argument(\"--nruns\", type=int, default=5)\n",
    "parser.add_argument(\"--numseeds\", type=int, default=5)\n",
    "parser.add_argument(\"--timelimitmin\", type=float, default=1)\n",
    "parser.add_argument(\"--rerank\", type=float, default=0.001)\n",
    "parser.add_argument(\"--dirout\", type=str, default=\"respso2\")\n",
    "parser.add_argument(\"--not_muted\", type=int, default=3)\n",
    "parser.add_argument(\"--n_jobs\", type=int, default=1)\n",
    "parser.add_argument(\"--n_jobs_autogluon\", type=int, default=64)\n",
    "parser.add_argument(\"--temp_autogluon\", type=str, default=\"temp_autogluon\")\n",
    "parser.add_argument(\"--train_size\", type=int, default=2000)\n",
    "\n",
    "PRUEBA = 'HYB'\n",
    "if PRUEBA == 'HYB':\n",
    "    # PSO\n",
    "    cmdline = \"--method HYB --rerank 0.001 --nump 15 --numseeds 5 --pcrossover 0.10\"\n",
    "    cmdline += \" --c1 1.193 --c2 1.193 --maxiter 200 --n_jobs 1 --dirout hyb_1001_12abr23_e27 --algorithm kridge\"\n",
    "    cmdline = cmdline.split(' ')\n",
    "    \n",
    "if PRUEBA == 'PSO':\n",
    "    # PSO\n",
    "    cmdline = \"--method PSO --rerank 0.001 --nump 15 --numseeds 5 --pcrossover 0.10\"\n",
    "    cmdline += \" --c1 1.193 --c2 1.193 --maxiter 200 --n_jobs 1 --dirout pso_16_22mar23 --algorithm kridge\"\n",
    "    cmdline = cmdline.split(' ')\n",
    "    \n",
    "if PRUEBA == 'BAYESOPT':\n",
    "    # Bayesian Optimization\n",
    "    cmdline = \"--database BD_soldadura_20feb23.csv --method BAYESOPT --algorithm kridge\"\n",
    "    cmdline += \" --maxiter 200 --nruns 10 --dirout bayes_kridge_10runs --n_jobs 1\"\n",
    "    cmdline = cmdline.split(' ')\n",
    "\n",
    "if PRUEBA == 'CONSOLE':\n",
    "    cmdline = sys.argv[1:]  # Read from console\n",
    "\n",
    "arg_in = parser.parse_args(cmdline)\n",
    "str_todos = '_'.join(str(arg_in).split(' '))\n",
    "str_todos = str_todos.replace(',', '')\n",
    "str_todos = str_todos.replace('Namespace(', '')\n",
    "str_todos = str_todos.replace(')', '')\n",
    "str_todos = str_todos.replace('=', '_')\n",
    "str_todos = str_todos.replace('.', '_')\n",
    "str_todos = str_todos.replace(\"'\", \"\")\n",
    "str_todos = str_todos.replace('\\\\r', '')\n",
    "print(str_todos)\n",
    "\n",
    "# Decreasing curve of worst\n",
    "if arg_in.pcrossover != None and arg_in.pcrossover != 0.0:\n",
    "    perc_malos = 0.80 * np.exp(-arg_in.pcrossover * np.arange(arg_in.maxiter))\n",
    "    perc_malos[perc_malos < 0.10] = 0.10\n",
    "else:\n",
    "    perc_malos = None\n",
    "    \n",
    "if arg_in.GPU == 'True':\n",
    "    arg_in.GPU = True\n",
    "    IS_GPU = 'YES'\n",
    "else:\n",
    "    arg_in.GPU = False\n",
    "    IS_GPU = 'NO'\n",
    "print('Using GPU=', IS_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8932d2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:11:51.512897Z",
     "start_time": "2023-04-12T14:11:51.502003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2023_04_23_19_11_02__HYB__kridge____15'\n",
      "'hyb_1001_12abr23_e27'\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y_%m_%d_%H_%M_%S_\")\n",
    "NAME_FILE = dt_string + '_' + arg_in.method + '__' + arg_in.algorithm + '__' + '__' + str(arg_in.nump)  # .join(arg_in[:2]) #+ str_todos\n",
    "NAME_FILE = ''.join(char for char in NAME_FILE if char in printable)\n",
    "print(repr(NAME_FILE))\n",
    "\n",
    "NUM_PARTICULAS = arg_in.nump\n",
    "DIR_SALIDA = str(arg_in.dirout).replace('\\\\r', '').replace('\\r', '')\n",
    "DIR_SALIDA = ''.join(char for char in DIR_SALIDA if char in printable)\n",
    "print(repr(DIR_SALIDA))\n",
    "\n",
    "if not os.path.exists(DIR_SALIDA):\n",
    "    os.mkdir(DIR_SALIDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d67c7",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcbd332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T14:11:51.532671Z",
     "start_time": "2023-04-12T14:11:51.519278Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def rmse_func(y_true, y_pred):\n",
    "    return -np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3691e",
   "metadata": {},
   "source": [
    "## Search Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9fc7b1",
   "metadata": {},
   "source": [
    "## Search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b76aa",
   "metadata": {},
   "source": [
    "### Search with Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c4f056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T02:19:01.688213Z",
     "start_time": "2023-04-12T14:11:51.638118Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice 180 2000\n",
      "'2023_04_23_19_11_02__HYB__kridge__slice_norm_reduc.csv__15'\n",
      "Processando Base de Datos con num_seed= 0\n",
      "0 2000 23000\n",
      "Running iteration 0\n",
      "Current best score: -0.13742466573381978\n",
      "  MeanVal = -0.1542441 ,   ValBest = -0.1374247 , ComplexBest = 341000000000.1462,  Time(min) = 0.1049806  \n",
      "\n",
      "Running iteration 1\n",
      "Current best score: -0.1373039056308599\n",
      "  MeanVal = -0.1521223 ,   ValBest = -0.1373039 , ComplexBest = 303000000000.2583,  Time(min) = 0.0122297  \n",
      "\n",
      "Running iteration 2\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1605993 ,   ValBest = -0.134219  , ComplexBest = 308000000000.1852,  Time(min) = 0.0105053  \n",
      "\n",
      "Running iteration 3\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1571092 ,   ValBest = -0.1349404 , ComplexBest = 300000000000.1756,  Time(min) = 0.0103054  \n",
      "\n",
      "Running iteration 4\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1631353 ,   ValBest = -0.1357979 , ComplexBest = 294000000000.16907,  Time(min) = 0.0110896  \n",
      "\n",
      "Running iteration 5\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1533811 ,   ValBest = -0.1359163 , ComplexBest = 296000000000.1695,  Time(min) = 0.0108239  \n",
      "\n",
      "Running iteration 6\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1532765 ,   ValBest = -0.1348247 , ComplexBest = 303000000000.17413,   Time(min) = 0.010735  \n",
      "\n",
      "Running iteration 7\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1516096 ,   ValBest = -0.1348357 , ComplexBest = 304000000000.1798,   Time(min) = 0.010184  \n",
      "\n",
      "Time limit reached. Stopped.\n",
      "RMSE test 0.13341878163550103\n",
      "Processando Base de Datos con num_seed= 1\n",
      "1 2000 23000\n",
      "Running iteration 0\n",
      "Current best score: -0.13742466573381978\n",
      "  MeanVal = -0.1542441 ,   ValBest = -0.1374247 , ComplexBest = 341000000000.1462,  Time(min) = 0.1047834  \n",
      "\n",
      "Running iteration 1\n",
      "Current best score: -0.1373039056308599\n",
      "  MeanVal = -0.1521223 ,   ValBest = -0.1373039 , ComplexBest = 303000000000.2583,  Time(min) = 0.0127506  \n",
      "\n",
      "Running iteration 2\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1605993 ,   ValBest = -0.134219  , ComplexBest = 308000000000.1852,  Time(min) = 0.0111394  \n",
      "\n",
      "Running iteration 3\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1571092 ,   ValBest = -0.1349404 , ComplexBest = 300000000000.1756,  Time(min) = 0.0102934  \n",
      "\n",
      "Running iteration 4\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1631353 ,   ValBest = -0.1357979 , ComplexBest = 294000000000.16907,  Time(min) = 0.0100646  \n",
      "\n",
      "Running iteration 5\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1533811 ,   ValBest = -0.1359163 , ComplexBest = 296000000000.1695,  Time(min) = 0.0113861  \n",
      "\n",
      "Running iteration 6\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1532765 ,   ValBest = -0.1348247 , ComplexBest = 303000000000.17413,  Time(min) = 0.0108643  \n",
      "\n",
      "Running iteration 7\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1516096 ,   ValBest = -0.1348357 , ComplexBest = 304000000000.1798,  Time(min) = 0.0111666  \n",
      "\n",
      "Time limit reached. Stopped.\n",
      "RMSE test 0.13341878163550103\n",
      "Processando Base de Datos con num_seed= 2\n",
      "2 2000 23000\n",
      "Running iteration 0\n",
      "Current best score: -0.13742466573381978\n",
      "  MeanVal = -0.1542441 ,   ValBest = -0.1374247 , ComplexBest = 341000000000.1462,  Time(min) = 0.1034698  \n",
      "\n",
      "Running iteration 1\n",
      "Current best score: -0.1373039056308599\n",
      "  MeanVal = -0.1521223 ,   ValBest = -0.1373039 , ComplexBest = 303000000000.2583,  Time(min) = 0.0126838  \n",
      "\n",
      "Running iteration 2\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1605993 ,   ValBest = -0.134219  , ComplexBest = 308000000000.1852,  Time(min) = 0.0104153  \n",
      "\n",
      "Running iteration 3\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1571092 ,   ValBest = -0.1349404 , ComplexBest = 300000000000.1756,  Time(min) = 0.0096179  \n",
      "\n",
      "Running iteration 4\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1631353 ,   ValBest = -0.1357979 , ComplexBest = 294000000000.16907,  Time(min) = 0.0101749  \n",
      "\n",
      "Running iteration 5\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1533811 ,   ValBest = -0.1359163 , ComplexBest = 296000000000.1695,  Time(min) = 0.0107579  \n",
      "\n",
      "Running iteration 6\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1532765 ,   ValBest = -0.1348247 , ComplexBest = 303000000000.17413,  Time(min) = 0.0110126  \n",
      "\n",
      "Running iteration 7\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1516096 ,   ValBest = -0.1348357 , ComplexBest = 304000000000.1798,  Time(min) = 0.0109615  \n",
      "\n",
      "Time limit reached. Stopped.\n",
      "RMSE test 0.13341878163550103\n",
      "Processando Base de Datos con num_seed= 3\n",
      "3 2000 23000\n",
      "Running iteration 0\n",
      "Current best score: -0.13742466573381978\n",
      "  MeanVal = -0.1542441 ,   ValBest = -0.1374247 , ComplexBest = 341000000000.1462,  Time(min) = 0.1026795  \n",
      "\n",
      "Running iteration 1\n",
      "Current best score: -0.1373039056308599\n",
      "  MeanVal = -0.1521223 ,   ValBest = -0.1373039 , ComplexBest = 303000000000.2583,  Time(min) = 0.0151479  \n",
      "\n",
      "Running iteration 2\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1605993 ,   ValBest = -0.134219  , ComplexBest = 308000000000.1852,  Time(min) = 0.0106349  \n",
      "\n",
      "Running iteration 3\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1571092 ,   ValBest = -0.1349404 , ComplexBest = 300000000000.1756,  Time(min) = 0.0106201  \n",
      "\n",
      "Running iteration 4\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1631353 ,   ValBest = -0.1357979 , ComplexBest = 294000000000.16907,  Time(min) = 0.0104414  \n",
      "\n",
      "Running iteration 5\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1533811 ,   ValBest = -0.1359163 , ComplexBest = 296000000000.1695,  Time(min) = 0.0112554  \n",
      "\n",
      "Running iteration 6\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1532765 ,   ValBest = -0.1348247 , ComplexBest = 303000000000.17413,  Time(min) = 0.0111503  \n",
      "\n",
      "Running iteration 7\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1516096 ,   ValBest = -0.1348357 , ComplexBest = 304000000000.1798,  Time(min) = 0.0108132  \n",
      "\n",
      "Time limit reached. Stopped.\n",
      "RMSE test 0.13341878163550103\n",
      "Processando Base de Datos con num_seed= 4\n",
      "4 2000 23000\n",
      "Running iteration 0\n",
      "Current best score: -0.13742466573381978\n",
      "  MeanVal = -0.1542441 ,   ValBest = -0.1374247 , ComplexBest = 341000000000.1462,  Time(min) = 0.1016403  \n",
      "\n",
      "Running iteration 1\n",
      "Current best score: -0.1373039056308599\n",
      "  MeanVal = -0.1521223 ,   ValBest = -0.1373039 , ComplexBest = 303000000000.2583,  Time(min) = 0.0128567  \n",
      "\n",
      "Running iteration 2\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1605993 ,   ValBest = -0.134219  , ComplexBest = 308000000000.1852,  Time(min) = 0.0107463  \n",
      "\n",
      "Running iteration 3\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1571092 ,   ValBest = -0.1349404 , ComplexBest = 300000000000.1756,  Time(min) = 0.0097488  \n",
      "\n",
      "Running iteration 4\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1631353 ,   ValBest = -0.1357979 , ComplexBest = 294000000000.16907,  Time(min) = 0.0104181  \n",
      "\n",
      "Running iteration 5\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1533811 ,   ValBest = -0.1359163 , ComplexBest = 296000000000.1695,  Time(min) = 0.0106148  \n",
      "\n",
      "Running iteration 6\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1532765 ,   ValBest = -0.1348247 , ComplexBest = 303000000000.17413,  Time(min) = 0.0102482  \n",
      "\n",
      "Running iteration 7\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1516096 ,   ValBest = -0.1348357 , ComplexBest = 304000000000.1798,  Time(min) = 0.0105477  \n",
      "\n",
      "Running iteration 8\n",
      "Current best score: -0.13421898773592048\n",
      "  MeanVal = -0.1533553 ,   ValBest = -0.1351353 , ComplexBest = 296000000000.17664,  Time(min) = 0.0101854  \n",
      "\n",
      "Time limit reached. Stopped.\n",
      "RMSE test 0.13341878163550103\n",
      "crime 180 1107\n",
      "'2023_04_23_19_11_02__HYB__kridge__crime_norm.csv__15'\n",
      "Processando Base de Datos con num_seed= 0\n",
      "0 1107 1108\n",
      "Running iteration 0\n",
      "Current best score: -0.444213232113417\n",
      "  MeanVal = -0.5135978 ,   ValBest = -0.4442132 , ComplexBest = 113000000001.62602,  Time(min) = 0.0940793  \n",
      "\n",
      "Running iteration 1\n",
      "Current best score: -0.4262558244787284\n",
      "  MeanVal = -0.4566735 ,   ValBest = -0.4262558 , ComplexBest = 103000000000.43571,  Time(min) = 0.0024197  \n",
      "\n",
      "Running iteration 2\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4456555 ,   ValBest = -0.4140446 , ComplexBest = 67000000001.00264,  Time(min) = 0.0029954  \n",
      "\n",
      "Running iteration 3\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4825442 ,   ValBest = -0.4154742 , ComplexBest = 65000000000.96054,  Time(min) = 0.0020719  \n",
      "\n",
      "Running iteration 4\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4784358 ,   ValBest = -0.4246282 , ComplexBest = 81000000000.78282,  Time(min) = 0.0029943  \n",
      "\n",
      "Running iteration 5\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4803399 ,   ValBest = -0.4163901 , ComplexBest = 72000000000.5991,  Time(min) = 0.0020975  \n",
      "\n",
      "Running iteration 6\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4838595 ,   ValBest = -0.4168088 , ComplexBest = 59000000000.577354,  Time(min) = 0.0026441  \n",
      "\n",
      "Running iteration 7\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4640297 ,   ValBest = -0.4199147 , ComplexBest = 67000000000.90645,  Time(min) = 0.0022617  \n",
      "\n",
      "Running iteration 8\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4631239 ,   ValBest = -0.4154856 , ComplexBest = 60000000000.85778,  Time(min) = 0.0023098  \n",
      "\n",
      "Running iteration 9\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4766845 ,   ValBest = -0.4154171 , ComplexBest = 57000000000.85799,  Time(min) = 0.0023323  \n",
      "\n",
      "Running iteration 10\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4569944 ,    ValBest = -0.41178  , ComplexBest = 62000000000.92426,  Time(min) = 0.0019648  \n",
      "\n",
      "Running iteration 11\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.469014  ,   ValBest = -0.4163124 , ComplexBest = 66000000001.27395,  Time(min) = 0.0019963  \n",
      "\n",
      "Running iteration 12\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4962777 ,   ValBest = -0.4169581 , ComplexBest = 64000000001.78788,  Time(min) = 0.0020098  \n",
      "\n",
      "Running iteration 13\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4592092 ,   ValBest = -0.4135819 , ComplexBest = 62000000000.927345,  Time(min) = 0.0022497  \n",
      "\n",
      "Running iteration 14\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4534616 ,   ValBest = -0.4186734 , ComplexBest = 63000000000.69384,   Time(min) = 0.002058  \n",
      "\n",
      "Running iteration 15\n",
      "Current best score: -0.41108688358385803\n",
      "  MeanVal = -0.4798629 ,   ValBest = -0.4110869 , ComplexBest = 60000000001.19221,  Time(min) = 0.0020521  \n",
      "\n",
      "Running iteration 16\n",
      "Current best score: -0.41108688358385803\n",
      "  MeanVal = -0.4710701 ,   ValBest = -0.4146248 , ComplexBest = 59000000001.03688,  Time(min) = 0.0025134  \n",
      "\n",
      "Running iteration 17\n",
      "Current best score: -0.4107049039139179\n",
      "  MeanVal = -0.4588759 ,   ValBest = -0.4107049 , ComplexBest = 57000000000.9866,  Time(min) = 0.0020982  \n",
      "\n",
      "Running iteration 18\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.464116  ,   ValBest = -0.4042912 , ComplexBest = 55000000000.84408,  Time(min) = 0.0020387  \n",
      "\n",
      "Running iteration 19\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4543187 ,   ValBest = -0.4126874 , ComplexBest = 57000000000.85346,  Time(min) = 0.0020041  \n",
      "\n",
      "Running iteration 20\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4880939 ,   ValBest = -0.4115565 , ComplexBest = 57000000001.15335,  Time(min) = 0.0020387  \n",
      "\n",
      "Running iteration 21\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4628263 ,   ValBest = -0.4058695 , ComplexBest = 56000000000.96989,  Time(min) = 0.0020483  \n",
      "\n",
      "Running iteration 22\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4578943 ,   ValBest = -0.4070185 , ComplexBest = 57000000000.8598,  Time(min) = 0.0020342  \n",
      "\n",
      "Running iteration 23\n",
      "Current best score: -0.4012881311588193\n",
      "  MeanVal = -0.4483137 ,   ValBest = -0.4012881 , ComplexBest = 55000000000.98431,  Time(min) = 0.0022824  \n",
      "\n",
      "Running iteration 24\n",
      "Current best score: -0.4012881311588193\n",
      "  MeanVal = -0.4625289 ,   ValBest = -0.4061173 , ComplexBest = 56000000001.09938,  Time(min) = 0.0020687  \n",
      "\n",
      "Running iteration 25\n",
      "Current best score: -0.3994738653734386\n",
      "  MeanVal = -0.4644452 ,   ValBest = -0.3994739 , ComplexBest = 48000000001.111275,  Time(min) = 0.0019696  \n",
      "\n",
      "Running iteration 26\n",
      "Current best score: -0.39685316019978745\n",
      "  MeanVal = -0.4283066 ,   ValBest = -0.3968532 , ComplexBest = 53000000000.84028,  Time(min) = 0.0019277  \n",
      "\n",
      "Running iteration 27\n",
      "Current best score: -0.39569139732416053\n",
      "  MeanVal = -0.4374533 ,   ValBest = -0.3956914 , ComplexBest = 57000000000.81589,  Time(min) = 0.0020638  \n",
      "\n",
      "Running iteration 28\n",
      "Current best score: -0.39569139732416053\n",
      "  MeanVal = -0.4364309 ,   ValBest = -0.3958547 , ComplexBest = 54000000000.96916,  Time(min) = 0.0023978  \n",
      "\n",
      "Running iteration 29\n",
      "Current best score: -0.39569139732416053\n",
      "  MeanVal = -0.4186345 ,   ValBest = -0.3959002 , ComplexBest = 60000000000.87635,  Time(min) = 0.0019801  \n",
      "\n",
      "Running iteration 30\n",
      "Current best score: -0.39569139732416053\n",
      "  MeanVal = -0.4679453 ,   ValBest = -0.3972691 , ComplexBest = 60000000000.83884,  Time(min) = 0.0023007  \n",
      "\n",
      "Running iteration 31\n",
      "Current best score: -0.3941865881941956\n",
      "  MeanVal = -0.4290853 ,   ValBest = -0.3941866 , ComplexBest = 55000000000.877304,  Time(min) = 0.0019348  \n",
      "\n",
      "Running iteration 32\n",
      "Current best score: -0.39028944083596\n",
      "  MeanVal = -0.4351738 ,   ValBest = -0.3902894 , ComplexBest = 50000000001.027985,  Time(min) = 0.0019131  \n",
      "\n",
      "Running iteration 33\n",
      "Current best score: -0.39028944083596\n",
      "  MeanVal = -0.4254339 ,   ValBest = -0.3954867 , ComplexBest = 51000000000.83076,  Time(min) = 0.0020441  \n",
      "\n",
      "Running iteration 34\n",
      "Current best score: -0.39028944083596\n",
      "  MeanVal = -0.4189297 ,   ValBest = -0.3929523 , ComplexBest = 54000000000.76679,   Time(min) = 0.001961  \n",
      "\n",
      "Running iteration 35\n",
      "Current best score: -0.39028944083596\n",
      "  MeanVal = -0.4139397 ,   ValBest = -0.3918788 , ComplexBest = 49000000000.715775,  Time(min) = 0.0018841  \n",
      "\n",
      "Running iteration 36\n",
      "Current best score: -0.38871356983377814\n",
      "  MeanVal = -0.4190007 ,   ValBest = -0.3887136 , ComplexBest = 53000000000.95063,  Time(min) = 0.0018396  \n",
      "\n",
      "Running iteration 37\n",
      "Current best score: -0.38871356983377814\n",
      "  MeanVal = -0.4210076 ,   ValBest = -0.3908103 , ComplexBest = 48000000000.77674,  Time(min) = 0.0019553  \n",
      "\n",
      "Running iteration 38\n",
      "Current best score: -0.38871356983377814\n",
      "  MeanVal = -0.4144708 ,   ValBest = -0.3899626 , ComplexBest = 52000000000.85454,  Time(min) = 0.0029809  \n",
      "\n",
      "Running iteration 39\n",
      "Current best score: -0.38871356983377814\n",
      "  MeanVal = -0.415814  ,   ValBest = -0.3890796 , ComplexBest = 53000000000.91989,   Time(min) = 0.001852  \n",
      "\n",
      "Time limit reached. Stopped.\n",
      "RMSE test 0.4267318301538674\n",
      "Processando Base de Datos con num_seed= 1\n",
      "1 1107 1108\n",
      "Running iteration 0\n",
      "Current best score: -0.444213232113417\n",
      "  MeanVal = -0.5135978 ,   ValBest = -0.4442132 , ComplexBest = 113000000001.62602,  Time(min) = 0.1040816  \n",
      "\n",
      "Running iteration 1\n",
      "Current best score: -0.4262558244787284\n",
      "  MeanVal = -0.4566735 ,   ValBest = -0.4262558 , ComplexBest = 103000000000.43571,  Time(min) = 0.0026061  \n",
      "\n",
      "Running iteration 2\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4456555 ,   ValBest = -0.4140446 , ComplexBest = 67000000001.00264,  Time(min) = 0.0026337  \n",
      "\n",
      "Running iteration 3\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4825442 ,   ValBest = -0.4154742 , ComplexBest = 65000000000.96054,  Time(min) = 0.0022857  \n",
      "\n",
      "Running iteration 4\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4784358 ,   ValBest = -0.4246282 , ComplexBest = 81000000000.78282,  Time(min) = 0.0024486  \n",
      "\n",
      "Running iteration 5\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4803399 ,   ValBest = -0.4163901 , ComplexBest = 72000000000.5991,  Time(min) = 0.0022401  \n",
      "\n",
      "Running iteration 6\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4838595 ,   ValBest = -0.4168088 , ComplexBest = 59000000000.577354,   Time(min) = 0.002393  \n",
      "\n",
      "Running iteration 7\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4640297 ,   ValBest = -0.4199147 , ComplexBest = 67000000000.90645,  Time(min) = 0.0021907  \n",
      "\n",
      "Running iteration 8\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4631239 ,   ValBest = -0.4154856 , ComplexBest = 60000000000.85778,  Time(min) = 0.0026593  \n",
      "\n",
      "Running iteration 9\n",
      "Current best score: -0.41404459968930035\n",
      "  MeanVal = -0.4766845 ,   ValBest = -0.4154171 , ComplexBest = 57000000000.85799,  Time(min) = 0.0022466  \n",
      "\n",
      "Running iteration 10\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4569944 ,    ValBest = -0.41178  , ComplexBest = 62000000000.92426,  Time(min) = 0.0029276  \n",
      "\n",
      "Running iteration 11\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.469014  ,   ValBest = -0.4163124 , ComplexBest = 66000000001.27395,  Time(min) = 0.0023559  \n",
      "\n",
      "Running iteration 12\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4962777 ,   ValBest = -0.4169581 , ComplexBest = 64000000001.78788,  Time(min) = 0.0022352  \n",
      "\n",
      "Running iteration 13\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4592092 ,   ValBest = -0.4135819 , ComplexBest = 62000000000.927345,  Time(min) = 0.0023339  \n",
      "\n",
      "Running iteration 14\n",
      "Current best score: -0.411780020607072\n",
      "  MeanVal = -0.4534616 ,   ValBest = -0.4186734 , ComplexBest = 63000000000.69384,  Time(min) = 0.0021981  \n",
      "\n",
      "Running iteration 15\n",
      "Current best score: -0.41108688358385803\n",
      "  MeanVal = -0.4798629 ,   ValBest = -0.4110869 , ComplexBest = 60000000001.19221,  Time(min) = 0.0021861  \n",
      "\n",
      "Running iteration 16\n",
      "Current best score: -0.41108688358385803\n",
      "  MeanVal = -0.4710701 ,   ValBest = -0.4146248 , ComplexBest = 59000000001.03688,  Time(min) = 0.0021824  \n",
      "\n",
      "Running iteration 17\n",
      "Current best score: -0.4107049039139179\n",
      "  MeanVal = -0.4588759 ,   ValBest = -0.4107049 , ComplexBest = 57000000000.9866,  Time(min) = 0.0029299  \n",
      "\n",
      "Running iteration 18\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.464116  ,   ValBest = -0.4042912 , ComplexBest = 55000000000.84408,  Time(min) = 0.0024758  \n",
      "\n",
      "Running iteration 19\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4543187 ,   ValBest = -0.4126874 , ComplexBest = 57000000000.85346,  Time(min) = 0.0021194  \n",
      "\n",
      "Running iteration 20\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4880939 ,   ValBest = -0.4115565 , ComplexBest = 57000000001.15335,  Time(min) = 0.0022229  \n",
      "\n",
      "Running iteration 21\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4628263 ,   ValBest = -0.4058695 , ComplexBest = 56000000000.96989,  Time(min) = 0.0020773  \n",
      "\n",
      "Running iteration 22\n",
      "Current best score: -0.4042912447219275\n",
      "  MeanVal = -0.4578943 ,   ValBest = -0.4070185 , ComplexBest = 57000000000.8598,  Time(min) = 0.0019862  \n",
      "\n",
      "Running iteration 23\n",
      "Current best score: -0.4012881311588193\n",
      "  MeanVal = -0.4483137 ,   ValBest = -0.4012881 , ComplexBest = 55000000000.98431,  Time(min) = 0.0020075  \n",
      "\n",
      "Running iteration 24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 90\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mprint\u001b[39m(num_seed, \u001b[39mlen\u001b[39m(X_train_val), \u001b[39mlen\u001b[39m(X_test))\n\u001b[0;32m     86\u001b[0m HYBparsimony_model \u001b[39m=\u001b[39m HYBparsimony(algorithm\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRidge\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     87\u001b[0m                                   features\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mcolumns,\n\u001b[0;32m     88\u001b[0m                                   rerank_error\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m,\n\u001b[0;32m     89\u001b[0m                                   verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m HYBparsimony_model\u001b[39m.\u001b[39;49mfit(X_train_val, y_train_val, time_limit\u001b[39m=\u001b[39;49m\u001b[39m0.20\u001b[39;49m)\n\u001b[0;32m     91\u001b[0m preds \u001b[39m=\u001b[39m HYBparsimony_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     92\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRMSE test\u001b[39m\u001b[39m\"\u001b[39m, mean_squared_error(y_test, preds))\n",
      "File \u001b[1;32mf:\\PISON_06\\CODIGO\\LIBRERIAS\\HYBparsimony\\HYBparsimony\\hybparsimony.py:297\u001b[0m, in \u001b[0;36mHYBparsimony.fit\u001b[1;34m(self, X, y, iter_ini, time_limit)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39msum(c\u001b[39m.\u001b[39mcolumns) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m         list_params\u001b[39m.\u001b[39mappend([c,X,y])\n\u001b[1;32m--> 297\u001b[0m results \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mstarmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness, list_params)  \u001b[39m## Aquí se hace el paralelismo.\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[39m# Recorremos los resultados\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[39mfor\u001b[39;00m fit, t \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, valid_particles):\n",
      "File \u001b[1;32mc:\\Users\\fjmartin\\Anaconda3\\lib\\multiprocessing\\pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    367\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[39m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, starmapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32mc:\\Users\\fjmartin\\Anaconda3\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fjmartin\\Anaconda3\\lib\\multiprocessing\\pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[1;32mc:\\Users\\fjmartin\\Anaconda3\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\fjmartin\\Anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tiempos = [['slice_norm_reduc.csv', 3, 2000, 378, 0.50], \n",
    "#            ['blog_norm.csv', 3, 2000, 276, 0.50], \n",
    "           ['crime_norm.csv', 3, 2000, 127, 0.50], \n",
    "#            ['tecator_norm.csv', 3, 2000, 124, 0.50],\n",
    "           ['ailerons_norm.csv', 3, 2000, 40, 0.50], \n",
    "#            ['puma_norm.csv', 3, 2000, 32, 0.50],\n",
    "           ['bank_norm.csv', 3, 2000, 32, 0.50], \n",
    "#            ['pol_norm.csv', 3, 2000, 26, 0.50],\n",
    "           \n",
    "#            ['cpu_act_norm.csv', 3, 2000, 21, 0.50],\n",
    "#            ['elevators_norm.csv', 3, 2000, 18, 0.50],\n",
    "#            ['meta_norm.csv', 3, 2000, 17, 0.50],\n",
    "#            ['bodyfat_norm.csv', 3, 2000, 14, 0.50], \n",
    "#            ['boston_norm.csv', 3, 2000, 13, 0.50],\n",
    "#            ['housing_norm.csv', 3, 2000, 13, 0.50],\n",
    "#            ['concrete_norm.csv', 3, 2000, 8, 0.50],\n",
    "#            ['no2_norm.csv', 3, 2000, 7, 0.50],\n",
    "#            ['pm10_norm.csv', 3, 2000, 7, 0.50],\n",
    "#            ['strike_norm.csv', 3, 2000, 6, 0.50]\n",
    "          ]\n",
    "    \n",
    "\n",
    "# # From Lee_Synthetic_All_10runs_27mar.ipynb\n",
    "# tiempos = [['ailerons_norm.csv', 3, 2000, 40, 1.0],\n",
    "#            ['crime_norm.csv', 3, 2000, 127, 0.4], \n",
    "#            ['blog_norm.csv', 3, 2000, 276, 0.6],\n",
    "#            ['slice_norm_reduc.csv', 3, 2000, 378, 0.60]]\n",
    "    \n",
    "\n",
    "run = 0\n",
    "for names_tiempo in tiempos:\n",
    "    name_db = names_tiempo[0].split('_')[0]\n",
    "    list_csv = os.listdir('.')\n",
    "    list_csv = [i for i in list_csv if f'{name_db}' in i]\n",
    "    file_db = list_csv[0]\n",
    "    time_limit = int(names_tiempo[1] * 60)  # Time limit in secs\n",
    "    \n",
    "    df_VAL = pd.read_csv(file_db)\n",
    "    train_val_size = df_VAL.shape[0]//2\n",
    "    if train_val_size>2000:\n",
    "        train_val_size = 2000\n",
    "    names_tiempo[2] = train_val_size\n",
    "    print(name_db, time_limit, train_val_size)\n",
    "    \n",
    "    res_modelos = []\n",
    "    GA_models = []\n",
    "    historical_todos = []\n",
    "    tiempo_inicial = time.time()\n",
    "    outer_res = []\n",
    "    \n",
    "    NAME_FILE = dt_string + '_' + arg_in.method + '__' + arg_in.algorithm + '__' + file_db + '__' + str(arg_in.nump)  # .join(arg_in[:2]) #+ str_todos\n",
    "    NAME_FILE = ''.join(char for char in NAME_FILE if char in printable)\n",
    "    print(repr(NAME_FILE))\n",
    "    \n",
    "    for num_seed in range(arg_in.numseeds):\n",
    "        print('Processando Base de Datos con num_seed=', num_seed)\n",
    "        df_VAL = pd.read_csv(file_db)\n",
    "        VAL = df_VAL.copy()\n",
    "        scaler_pruebas = StandardScaler()\n",
    "        VAL_norm = pd.DataFrame(scaler_pruebas.fit_transform(VAL), columns=VAL.columns)\n",
    "\n",
    "        TST_RMSE_ITER = []\n",
    "        NUM_FEATS = []\n",
    "        \n",
    "        # Con selección\n",
    "        input_names = VAL_norm.columns[:-1]\n",
    "        target_name = VAL_norm.columns[-1]\n",
    "\n",
    "        X = VAL_norm[input_names]\n",
    "        y = VAL_norm[target_name]\n",
    "        seed_everything(num_seed)\n",
    "\n",
    "         # IMPORTANTE: En KFOLD_HYB_AUTOGLUON cojo 2000 filas de train_val y el resto de test...salvo que se especifique\n",
    "        # el parámetro train_size (que será el número de filas a pillar de la BD).\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                                    train_size = names_tiempo[2] / len(X), \n",
    "                                                                    random_state=12345)\n",
    "        size_train_val = len(X_train_val)\n",
    "        size_test = len(X_test)\n",
    "\n",
    "        model_name = 'KFOLD_HYB_AUTOGLUON'\n",
    "        selec_input_folds=[]\n",
    "        VAL_RMSE_ACC=[]\n",
    "        print(num_seed, len(X_train_val), len(X_test))\n",
    "\n",
    "        HYBparsimony_model = HYBparsimony(algorithm='Ridge',\n",
    "                                          features=X.columns,\n",
    "                                          rerank_error=0.001,\n",
    "                                          verbose=1)\n",
    "        HYBparsimony_model.fit(X_train_val, y_train_val, time_limit=0.20)\n",
    "        preds = HYBparsimony_model.predict(X_test)\n",
    "        print(\"RMSE test\", mean_squared_error(y_test, preds))\n",
    "    \n",
    "\n",
    "    #     model.fit(X_train_val[selec_input].values, y_train_val.values)\n",
    "    #     y_test_pred = model.predict(X_test[selec_input].values)\n",
    "    #     OUTER_RMSE = mean_squared_error(y_test.values, y_test_pred, squared=False)\n",
    "    #     OUTER_MAE = mean_absolute_error(y_test.values, y_test_pred)\n",
    "    #     OUTER_MAPE = mean_absolute_percentage_error(y_test.values, y_test_pred) * 100\n",
    "    #     mean_outer['OUTER_RMSE'] = OUTER_RMSE\n",
    "    #     mean_outer['OUTER_MAE'] = OUTER_MAE\n",
    "    #     mean_outer['OUTER_MAPE'] = OUTER_MAPE\n",
    "    #     outer_res.append(mean_outer)\n",
    "    # outer_res = pd.concat(outer_res)\n",
    "    # outer_res.to_csv(DIR_SALIDA + '/' + NAME_FILE + '_' + name_db.split('_')[0] + '_outer.csv', index=False)\n",
    "    # print(name_db)\n",
    "    # display(outer_res[['mean_VAL_RMSE_FOLD', 'mean_TST_RMSE_FOLD', 'mean_TST_RMSE', 'OUTER_RMSE']].mean())\n",
    "    # print('##########################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYBparsimony_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe219da",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ridge' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m HYBparsimony_model\u001b[39m.\u001b[39;49mbest_model\u001b[39m.\u001b[39;49mget_feature_names()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Ridge' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "HYBparsimony_model.best_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2175e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1e9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b51d1eb",
   "metadata": {},
   "source": [
    "## Obtain Outer Models by Selecting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f531d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T07:39:27.511997Z",
     "start_time": "2023-04-13T07:39:27.500475Z"
    }
   },
   "outputs": [],
   "source": [
    "path_files = 'hyb_1001_12abr23_e27/'\n",
    "archivos = os.listdir(path_files)\n",
    "archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd320b7f",
   "metadata": {},
   "source": [
    "### Bayesian with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da629615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T07:39:30.364902Z",
     "start_time": "2023-04-13T07:39:30.351659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimize with BayesianOptimization\n",
    "def bayes_cv(chromosome_all_ones):\n",
    "    global X_train_val, y_train_val\n",
    "    res_folds = []\n",
    "    kf = KFold(n_splits=arg_in.numseeds, shuffle=True, random_state=1234)\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X_train_val)):\n",
    "        X_train = X_train_val.iloc[train_index].reset_index(drop=True)\n",
    "        y_train = y_train_val.iloc[train_index].reset_index(drop=True)\n",
    "        X_val = X_train_val.iloc[val_index].reset_index(drop=True)\n",
    "        y_val = y_train_val.iloc[val_index].reset_index(drop=True)\n",
    "        res_folds.append(fitness_fun(chromosome_all_ones, X_train, y_train, X_val, y_val, 0, 0)[0][1])\n",
    "    res_folds = np.array(res_folds)\n",
    "    return np.mean(res_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918b4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T07:38:06.865637Z",
     "start_time": "2023-04-13T07:38:06.856139Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_fun(hidden_layer_sizes, alpha):\n",
    "    params_opt = dict(hidden_layer_sizes=int(hidden_layer_sizes),\n",
    "                      alpha=alpha,\n",
    "                      solver='lbfgs',\n",
    "                      activation='logistic',\n",
    "                      n_iter_no_change=20,\n",
    "                      tol=1e-5,\n",
    "                      random_state=1234,\n",
    "                      max_iter=5000)\n",
    "    chromosome_all_ones = pd.Series(dict(columns=(np.ones(len(input_names)) == 1), params=params_opt))\n",
    "    return bayes_cv(chromosome_all_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d0e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T07:40:26.854950Z",
     "start_time": "2023-04-13T07:40:26.833459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ridge\n",
    "if arg_in.algorithm == 'ridge':\n",
    "    def optimize_fun(alpha):\n",
    "        chromosome_all_ones = pd.Series(\n",
    "            dict(columns=(np.ones(len(input_names)) == 1), params=dict(alpha=alpha, tol=1e-4)))\n",
    "        return bayes_cv(chromosome_all_ones)  \n",
    "    \n",
    "# KernelRidge\n",
    "if arg_in.algorithm == 'kridge':\n",
    "    def optimize_fun(alpha, gamma):\n",
    "        chromosome_all_ones = pd.Series(\n",
    "            dict(columns=(np.ones(len(input_names)) == 1), params=dict(alpha=alpha, gamma=gamma, kernel=\"rbf\")))\n",
    "        return bayes_cv(chromosome_all_ones)  # Antes era res[0][0], pero ahora nos quedamos con res[0][1] porque queremos el error en X_val.\n",
    "\n",
    "# SVR\n",
    "if arg_in.algorithm == 'svr':\n",
    "    def optimize_fun(C, gamma):\n",
    "        chromosome_all_ones = pd.Series(\n",
    "            dict(columns=(np.ones(len(input_names)) == 1), params=dict(C=C, gamma=gamma, kernel=\"rbf\")))\n",
    "        return bayes_cv(chromosome_all_ones)  # Antes era res[0][0], pero ahora nos quedamos con res[0][1] porque queremos el error en X_val.\n",
    "    \n",
    "# DecisionTreeRegressor\n",
    "if arg_in.algorithm == 'dtr':\n",
    "    def optimize_fun(max_depth, min_impurity_decrease):\n",
    "        chromosome_all_ones = pd.Series(\n",
    "            dict(columns=(np.ones(len(input_names)) == 1), params=dict(max_depth=max_depth, min_impurity_decrease=min_impurity_decrease)))\n",
    "        return bayes_cv(chromosome_all_ones)  # Antes era res[0][0], pero ahora nos quedamos con res[0][1] porque queremos el error en X_val.   \n",
    "    \n",
    "# RandomForest\n",
    "if arg_in.algorithm == 'rf':\n",
    "    def optimize_fun(max_depth, n_estimators, min_impurity_decrease):\n",
    "        chromosome_all_ones = pd.Series(\n",
    "            dict(columns=(np.ones(len(input_names)) == 1), params=dict(max_depth=max_depth, \n",
    "                                                                       n_estimators=n_estimators,\n",
    "                                                                       min_impurity_decrease=min_impurity_decrease)))\n",
    "        return bayes_cv(chromosome_all_ones)  # Antes era res[0][0], pero ahora nos quedamos con res[0][1] porque queremos el error en X_val.        \n",
    "\n",
    "# MultilayerPerceptron\n",
    "if arg_in.algorithm == 'mlp':\n",
    "    def optimize_fun(hidden_layer_sizes, alpha):\n",
    "        params_opt = dict(hidden_layer_sizes=int(hidden_layer_sizes),\n",
    "                          alpha=alpha,\n",
    "                          solver='lbfgs',\n",
    "                          activation='logistic',\n",
    "                          n_iter_no_change=20,\n",
    "                          tol=1e-5,\n",
    "                          random_state=1234,\n",
    "                          max_iter=5000)\n",
    "        chromosome_all_ones = pd.Series(dict(columns=(np.ones(len(input_names)) == 1), params=params_opt))\n",
    "        return bayes_cv(chromosome_all_ones) # Antes era res[0][0], pero ahora nos quedamos con res[0][1] porque queremos el error en X_val.\n",
    "\n",
    "def desnorm_y(y_pred):\n",
    "    return ((y_pred*y_orig_sqrt_std)+y_orig_sqrt_mean)**2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604bd6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T18:05:33.491282Z",
     "start_time": "2023-04-14T08:00:55.106142Z"
    }
   },
   "outputs": [],
   "source": [
    "for thr_features in [0.00, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70]:\n",
    "    run = 0\n",
    "    features_list = []\n",
    "    for names_tiempo in tiempos:\n",
    "        name_db = names_tiempo[0].split('_')[0]\n",
    "        list_csv = os.listdir('.')\n",
    "        list_csv = [i for i in list_csv if f'{name_db}' in i]\n",
    "        file_db = list_csv[0]\n",
    "        time_limit = int(names_tiempo[1] * 60)  # Time limit in secs\n",
    "        train_val_size = names_tiempo[2]\n",
    "        print(name_db, time_limit, train_val_size)\n",
    "\n",
    "        NAME_FILE = dt_string + '_' + arg_in.method + '__' + arg_in.algorithm + '__' + file_db + '__' + str(arg_in.nump)  # .join(arg_in[:2]) #+ str_todos\n",
    "        NAME_FILE = ''.join(char for char in NAME_FILE if char in printable)\n",
    "        print(repr(NAME_FILE))\n",
    "\n",
    "        res_modelos = []\n",
    "        GA_models = []\n",
    "        historical_todos = []\n",
    "        tiempo_inicial = time.time()\n",
    "        outer_res = []\n",
    "\n",
    "        for num_seed in range(arg_in.numseeds):\n",
    "            print('Procesando Base de Datos con num_seed=', num_seed)\n",
    "            df_VAL = pd.read_csv(file_db)\n",
    "            print(df_VAL.shape)\n",
    "            train_val_size = df_VAL.shape[0]//2\n",
    "            if train_val_size>2000:\n",
    "                train_val_size = 2000\n",
    "            names_tiempo[2] = train_val_size\n",
    "            print(name_db, time_limit, train_val_size)\n",
    "            num_feats = df_VAL.shape[1]-1\n",
    "\n",
    "            df_VAL = pd.read_csv(file_db)\n",
    "            VAL = df_VAL.copy()\n",
    "            scaler_pruebas = StandardScaler()\n",
    "            VAL_norm = pd.DataFrame(scaler_pruebas.fit_transform(VAL), columns=VAL.columns)\n",
    "\n",
    "            TST_RMSE_ITER = []\n",
    "            NUM_FEATS = []\n",
    "\n",
    "            # Con selección\n",
    "            input_names = VAL_norm.columns[:-1]\n",
    "            target_name = VAL_norm.columns[-1]\n",
    "\n",
    "            X = VAL_norm[input_names]\n",
    "            y = VAL_norm[target_name]\n",
    "            seed_everything(num_seed)\n",
    "\n",
    "             # IMPORTANTE: En KFOLD_HYB_AUTOGLUON cojo 2000 filas de train_val y el resto de test...salvo que se especifique\n",
    "            # el parámetro train_size (que será el número de filas a pillar de la BD).\n",
    "            X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                                        train_size = names_tiempo[2] / len(X), \n",
    "                                                                        random_state=12345)\n",
    "            size_train_val = len(X_train_val)\n",
    "            size_test = len(X_test)\n",
    "\n",
    "            model_name = 'KFOLD_HYB_AUTOGLUON'\n",
    "            selec_input_folds=[]\n",
    "            VAL_RMSE_ACC=[]\n",
    "            # En este caso, hacemos los X folds (fold es el numseeds)\n",
    "            kf = KFold(n_splits=arg_in.numseeds, shuffle=False)\n",
    "\n",
    "            file_name = [i for i in archivos if name_db in i and 'results' in i][0]\n",
    "            results_name = path_files + file_name\n",
    "            res_final = pd.read_csv(results_name) #DIR_SALIDA + '/' + NAME_FILE + '_results.csv')\n",
    "    #         display(res_final)\n",
    "\n",
    "            def convierte_str(cadena):\n",
    "                return np.array(eval(cadena.replace(' ',',').replace('\\n','').replace('nan','0')))\n",
    "\n",
    "\n",
    "            # FINAL MODEL FOR EACH OUTER WITH MEAN PARAMS\n",
    "            if arg_in.algorithm == 'mlp':\n",
    "                only_outer = res_final.query('num_seed==@num_seed').reset_index(drop=True)\n",
    "                only_outer['best_solution'] = only_outer['best_solution'].apply(lambda x: convierte_str(x))\n",
    "                only_outer['complex_best'] =  only_outer['best_solution'].apply(lambda x: x[2]).values\n",
    "                only_outer['hidden'] =  only_outer['best_solution'].apply(lambda x: x[3]).values\n",
    "                only_outer['alpha'] =  only_outer['best_solution'].apply(lambda x: 10**x[4]).values\n",
    "                only_outer['features'] =  only_outer['best_solution'].apply(lambda x: x[-len(input_names):]).values\n",
    "                mean_outer = only_outer[['VAL_RMSE_FOLD', 'VAL_MAE', 'VAL_MAPE', 'TST_RMSE_FOLD',\n",
    "                                         'TST_RMSE', 'TST_MAE', 'TST_MAPE',\n",
    "                                        'complex_best', 'hidden', 'alpha']].aggregate(['mean','std'])\n",
    "                fil0 = mean_outer.iloc[0]\n",
    "                fil0.index = ['mean_'+col for col in mean_outer.columns]\n",
    "                fil1 = mean_outer.iloc[1]\n",
    "                fil1.index = ['std_'+col for col in mean_outer.columns]\n",
    "                mean_outer = pd.concat(\n",
    "                    [only_outer[['method', 'database', 'namevar', 'size_train_val', 'size_test',\n",
    "                           'num_input_feats', 'num_seed', 'innerfold', 'run', 'model_name',\n",
    "                           'rerank_error', 'time', 'last_iter', 'mejor_val',\n",
    "                           'numindiv', 'maxiter', 'early', 'Lambda', 'c1', 'c2', 'IWmax', 'IWmin',\n",
    "                           'K', 'globthr', 'CVrep', 'CVspl', 'nruns', 'pcrossover_elitists',\n",
    "                           'pcrossover', 'best_solution']].head(1),\n",
    "                     pd.DataFrame(pd.concat([fil0,fil1])).transpose()],axis=1)\n",
    "\n",
    "                # Model with mean of hyperparameters\n",
    "                # Entrenamos con TRAIN+VAL y medimos el error con TST\n",
    "                model = MLPRegressor()\n",
    "                model.hidden_layer_sizes = int(mean_outer['mean_hidden'].values[0])\n",
    "                model.alpha = mean_outer['mean_alpha'].values[0]\n",
    "\n",
    "            if arg_in.algorithm == 'kridge':\n",
    "                only_outer = res_final.query('num_seed==@num_seed').reset_index(drop=True)\n",
    "                only_outer['best_solution'] = only_outer['best_solution'].apply(lambda x: convierte_str(x))\n",
    "                only_outer['complex_best'] =  only_outer['best_solution'].apply(lambda x: x[2]).values\n",
    "                only_outer['alpha'] =  only_outer['best_solution'].apply(lambda x: 10**x[3]).values\n",
    "                only_outer['gamma'] =  only_outer['best_solution'].apply(lambda x: 10**x[4]).values\n",
    "                only_outer['features'] =  only_outer['best_solution'].apply(lambda x: x[-len(input_names):]).values\n",
    "                mean_outer = only_outer[['VAL_RMSE_FOLD', 'VAL_MAE', 'VAL_MAPE', 'TST_RMSE_FOLD',\n",
    "                                         'TST_RMSE', 'TST_MAE', 'TST_MAPE',\n",
    "                                        'complex_best', 'alpha', 'gamma']].aggregate(['mean','std'])\n",
    "                fil0 = mean_outer.iloc[0]\n",
    "                fil0.index = ['mean_'+col for col in mean_outer.columns]\n",
    "                fil1 = mean_outer.iloc[1]\n",
    "                fil1.index = ['std_'+col for col in mean_outer.columns]\n",
    "                mean_outer = pd.concat(\n",
    "                    [only_outer[['method', 'database', 'namevar', 'size_train_val', 'size_test',\n",
    "                           'num_input_feats', 'num_seed', 'innerfold', 'run', 'model_name',\n",
    "                           'rerank_error', 'time', 'last_iter', 'mejor_val',\n",
    "                           'numindiv', 'maxiter', 'early', 'Lambda', 'c1', 'c2', 'IWmax', 'IWmin',\n",
    "                           'K', 'globthr', 'CVrep', 'CVspl', 'nruns', 'pcrossover_elitists',\n",
    "                           'pcrossover', 'best_solution']].head(1),\n",
    "                     pd.DataFrame(pd.concat([fil0,fil1])).transpose()],axis=1)\n",
    "\n",
    "                # Model with mean of hyperparameters\n",
    "                # Entrenamos con TRAIN+VAL y medimos el error con TST\n",
    "                model = res_search_model.best_model\n",
    "                model.alpha = mean_outer['mean_alpha'].values[0]\n",
    "                model.gamma = mean_outer['mean_gamma'].values[0]\n",
    "\n",
    "    #         selec_features = input_names[(np.stack(only_outer['features'].values)>0.50).mean(axis=0)>=0.50]\n",
    "            selec_features = input_names[(np.mean(np.stack(only_outer['features'].values),axis=0)>= thr_features)]\n",
    "            print(f'DB={name_db} train_val_size={train_val_size} ncols={len(input_names)} NFS={len(selec_features)}')\n",
    "            features_list.append(dict(name_db=name_db,\n",
    "                                      num_feats=num_feats,\n",
    "                                      num_selec = len(selec_features),\n",
    "\n",
    "                                      file_db=file_db,\n",
    "                                      results_name=results_name,\n",
    "                                      selec_features=np.array(selec_features)\n",
    "                                     ))\n",
    "\n",
    "    features_list = pd.DataFrame(features_list)\n",
    "\n",
    "    # Search with Bayesian\n",
    "    arg_in.maxiter = 200\n",
    "    run = 0\n",
    "    res = []\n",
    "    for names_tiempo in tiempos:\n",
    "        name_db = names_tiempo[0].split('_')[0]\n",
    "        list_csv = os.listdir('.')\n",
    "        list_csv = [i for i in list_csv if f'{name_db}' in i]\n",
    "        file_db = list_csv[0]\n",
    "        time_limit = int(names_tiempo[1] * 60)  # Time limit in secs\n",
    "        train_val_size = names_tiempo[2]\n",
    "        print(name_db, time_limit, train_val_size)\n",
    "\n",
    "        NAME_FILE = dt_string + '_' + arg_in.method + '__' + arg_in.algorithm + '__' + file_db + '__' + str(arg_in.nump)  # .join(arg_in[:2]) #+ str_todos\n",
    "        NAME_FILE = ''.join(char for char in NAME_FILE if char in printable)\n",
    "        print(repr(NAME_FILE))\n",
    "\n",
    "        res_modelos = []\n",
    "        GA_models = []\n",
    "        historical_todos = []\n",
    "        tiempo_inicial = time.time()\n",
    "        outer_res = []\n",
    "\n",
    "        for num_seed in range(arg_in.numseeds):\n",
    "            print('Procesando Base de Datos=', name_db,' con num_seed=', num_seed, 'thr_features=', thr_features)\n",
    "            df_VAL = pd.read_csv(file_db)\n",
    "            print(df_VAL.shape)\n",
    "            train_val_size = df_VAL.shape[0]//2\n",
    "            if train_val_size>2000:\n",
    "                train_val_size = 2000\n",
    "            names_tiempo[2] = train_val_size\n",
    "\n",
    "            num_feats = df_VAL.shape[1]-1\n",
    "\n",
    "            df_VAL = pd.read_csv(file_db)\n",
    "            VAL = df_VAL.copy()\n",
    "            scaler_pruebas = StandardScaler()\n",
    "            VAL_norm = pd.DataFrame(scaler_pruebas.fit_transform(VAL), columns=VAL.columns)\n",
    "\n",
    "            TST_RMSE_ITER = []\n",
    "            NUM_FEATS = []\n",
    "\n",
    "            # Con selección\n",
    "    #         input_names = VAL_norm.columns[:-1]\n",
    "            input_names = features_list.query('name_db==@name_db').iloc[num_seed]['selec_features']\n",
    "            target_name = VAL_norm.columns[-1]\n",
    "            print(f'DB={name_db} train_val_size={train_val_size} ncols={df_VAL.shape[1]-1} NFS={len(input_names)}')\n",
    "            if len(input_names)==0:\n",
    "                input_names = VAL_norm.columns[:2]\n",
    "            X = VAL_norm[input_names]\n",
    "            y = VAL_norm[target_name]\n",
    "            seed_everything(num_seed)\n",
    "\n",
    "            # IMPORTANTE: En KFOLD_HYB_AUTOGLUON cojo 2000 filas de train_val y el resto de test...salvo que se especifique\n",
    "            # el parámetro train_size (que será el número de filas a pillar de la BD).\n",
    "            X_train_val, X_test, y_train_val, y_test = train_test_split(X[input_names], y, \n",
    "                                                                        train_size = names_tiempo[2] / len(X), \n",
    "                                                                        random_state=12345)\n",
    "            size_train_val = len(X_train_val)\n",
    "            size_test = len(X_test)\n",
    "\n",
    "            model_name = 'KFOLD_HYB_AUTOGLUON'\n",
    "            selec_input_folds=[]\n",
    "            VAL_RMSE_ACC=[]\n",
    "\n",
    "            # Search With CV\n",
    "            # --------------\n",
    "            pbounds = dict()\n",
    "            for parm in params:\n",
    "                if params[parm]['type'] <= 1:\n",
    "                    pbounds[parm] = params[parm]['range']\n",
    "\n",
    "            tic = time.time()\n",
    "            optimizer = BayesianOptimization(f=optimize_fun,\n",
    "                                             pbounds=pbounds,\n",
    "                                             random_state=1234,\n",
    "                                             allow_duplicate_points=True) # Añado allow_duplicate_points=True para evitar errores que salían.\n",
    "            optimizer.maximize(init_points=10, n_iter=arg_in.maxiter - 10)\n",
    "            # Keep elapsed time in minutes\n",
    "            tac = time.time()\n",
    "            elapsed_time = (tac - tic) / 60.0\n",
    "            print('Elapsed_time:', elapsed_time)\n",
    "            print('Best:', optimizer.max)\n",
    "\n",
    "            if arg_in.algorithm == 'mlp':\n",
    "                # Best model\n",
    "                hidden_layer_sizes = optimizer.max['params']['hidden_layer_sizes']\n",
    "                alpha = 10.0**optimizer.max['params']['alpha']\n",
    "                params_opt = dict(hidden_layer_sizes=int(hidden_layer_sizes),\n",
    "                                  alpha=alpha,\n",
    "                                  solver='lbfgs',\n",
    "                                  activation='logistic',\n",
    "                                  n_iter_no_change=20,\n",
    "                                  tol=1e-5,\n",
    "                                  random_state=1234,\n",
    "                                  max_iter=5000)\n",
    "                params_indiv = [optimizer.max['params']['hidden_layer_sizes'], optimizer.max['params']['alpha']]\n",
    "                model = MLPRegressor(**params_opt)\n",
    "            \n",
    "                # Entrena con innerfolds y saca el error con test\n",
    "                model.fit(X_train_val[input_names].values, y_train_val.values)\n",
    "                y_test_pred = model.predict(X_test[input_names].values)\n",
    "                OUTER_RMSE = mean_squared_error(y_test.values, y_test_pred, squared=False)\n",
    "                OUTER_MAE = mean_absolute_error(y_test.values, y_test_pred)\n",
    "                OUTER_MAPE = mean_absolute_percentage_error(y_test.values, y_test_pred) * 100\n",
    "                print(OUTER_RMSE, OUTER_MAE, OUTER_MAPE)\n",
    "                res.append(dict(name_db=name_db,\n",
    "                                CV_RMSE = -optimizer.max['target'],\n",
    "                                OUTER_RMSE=OUTER_RMSE,\n",
    "                                OUTER_MAE=OUTER_MAE,\n",
    "                                OUTER_MAPE=OUTER_MAPE,\n",
    "                                train_val_size=train_val_size,\n",
    "                                test_size=len(X_test),\n",
    "                                ncols=df_VAL.shape[1]-1,\n",
    "                                NFs=len(input_names),\n",
    "                                hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                alpha=alpha,\n",
    "                                num_seed=num_seed,\n",
    "                                input_names=input_names))\n",
    "\n",
    "            if arg_in.algorithm == 'kridge':\n",
    "                # Best model\n",
    "                alpha = 10.0**optimizer.max['params']['alpha']\n",
    "                gamma = 10.0**optimizer.max['params']['gamma']\n",
    "                params_opt = dict(alpha=alpha, \n",
    "                                  gamma=gamma, \n",
    "                                  kernel=\"rbf\")\n",
    "                params_indiv = [optimizer.max['params']['alpha'], optimizer.max['params']['gamma']]\n",
    "                model = KernelRidge(**params_opt)\n",
    "                \n",
    "                # Entrena con innerfolds y saca el error con test\n",
    "                model.fit(X_train_val[input_names].values, y_train_val.values)\n",
    "                y_test_pred = model.predict(X_test[input_names].values)\n",
    "                OUTER_RMSE = mean_squared_error(y_test.values, y_test_pred, squared=False)\n",
    "                OUTER_MAE = mean_absolute_error(y_test.values, y_test_pred)\n",
    "                OUTER_MAPE = mean_absolute_percentage_error(y_test.values, y_test_pred) * 100\n",
    "                print(OUTER_RMSE, OUTER_MAE, OUTER_MAPE)\n",
    "                res.append(dict(name_db=name_db,\n",
    "                                CV_RMSE = -optimizer.max['target'],\n",
    "                                OUTER_RMSE=OUTER_RMSE,\n",
    "                                OUTER_MAE=OUTER_MAE,\n",
    "                                OUTER_MAPE=OUTER_MAPE,\n",
    "                                train_val_size=train_val_size,\n",
    "                                test_size=len(X_test),\n",
    "                                ncols=df_VAL.shape[1]-1,\n",
    "                                NFs=len(input_names),\n",
    "                                alpha=alpha,\n",
    "                                gamma=gamma,\n",
    "                                num_seed=num_seed,\n",
    "                                input_names=input_names))\n",
    "            res_total = pd.DataFrame(res)\n",
    "            res_total.to_csv(f'res_bayes_after_pso_thrfeats_{thr_features}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426794f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:49:32.895871Z",
     "start_time": "2023-04-16T11:49:32.721325Z"
    }
   },
   "outputs": [],
   "source": [
    "res_total.groupby('name_db').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbddccd5",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f369bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T12:18:02.228537Z",
     "start_time": "2023-04-16T12:16:51.668903Z"
    }
   },
   "outputs": [],
   "source": [
    "features_list_thr = []\n",
    "for thr_features in [0.00, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70]:\n",
    "    run = 0\n",
    "    for names_tiempo in tiempos:\n",
    "        name_db = names_tiempo[0].split('_')[0]\n",
    "        list_csv = os.listdir('.')\n",
    "        list_csv = [i for i in list_csv if f'{name_db}' in i]\n",
    "        file_db = list_csv[0]\n",
    "        time_limit = int(names_tiempo[1] * 60)  # Time limit in secs\n",
    "        train_val_size = names_tiempo[2]\n",
    "        print(name_db, time_limit, train_val_size)\n",
    "\n",
    "        NAME_FILE = dt_string + '_' + arg_in.method + '__' + arg_in.algorithm + '__' + file_db + '__' + str(arg_in.nump)  # .join(arg_in[:2]) #+ str_todos\n",
    "        NAME_FILE = ''.join(char for char in NAME_FILE if char in printable)\n",
    "        print(repr(NAME_FILE))\n",
    "\n",
    "        res_modelos = []\n",
    "        GA_models = []\n",
    "        historical_todos = []\n",
    "        tiempo_inicial = time.time()\n",
    "        outer_res = []\n",
    "\n",
    "        for num_seed in range(arg_in.numseeds):\n",
    "            print('Procesando Base de Datos con num_seed=', num_seed)\n",
    "            df_VAL = pd.read_csv(file_db)\n",
    "            print(df_VAL.shape)\n",
    "            train_val_size = df_VAL.shape[0]//2\n",
    "            if train_val_size>2000:\n",
    "                train_val_size = 2000\n",
    "            names_tiempo[2] = train_val_size\n",
    "            print(name_db, time_limit, train_val_size)\n",
    "            num_feats = df_VAL.shape[1]-1\n",
    "\n",
    "            df_VAL = pd.read_csv(file_db)\n",
    "            VAL = df_VAL.copy()\n",
    "            scaler_pruebas = StandardScaler()\n",
    "            VAL_norm = pd.DataFrame(scaler_pruebas.fit_transform(VAL), columns=VAL.columns)\n",
    "\n",
    "            TST_RMSE_ITER = []\n",
    "            NUM_FEATS = []\n",
    "\n",
    "            # Con selección\n",
    "            input_names = VAL_norm.columns[:-1]\n",
    "            target_name = VAL_norm.columns[-1]\n",
    "\n",
    "            X = VAL_norm[input_names]\n",
    "            y = VAL_norm[target_name]\n",
    "            seed_everything(num_seed)\n",
    "\n",
    "             # IMPORTANTE: En KFOLD_HYB_AUTOGLUON cojo 2000 filas de train_val y el resto de test...salvo que se especifique\n",
    "            # el parámetro train_size (que será el número de filas a pillar de la BD).\n",
    "            X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                                        train_size = names_tiempo[2] / len(X), \n",
    "                                                                        random_state=12345)\n",
    "            size_train_val = len(X_train_val)\n",
    "            size_test = len(X_test)\n",
    "\n",
    "            model_name = 'KFOLD_HYB_AUTOGLUON'\n",
    "            selec_input_folds=[]\n",
    "            VAL_RMSE_ACC=[]\n",
    "            # En este caso, hacemos los X folds (fold es el numseeds)\n",
    "            kf = KFold(n_splits=arg_in.numseeds, shuffle=False)\n",
    "\n",
    "            file_name = [i for i in archivos if name_db in i and 'results' in i][0]\n",
    "            results_name = path_files + file_name\n",
    "            res_final = pd.read_csv(results_name) #DIR_SALIDA + '/' + NAME_FILE + '_results.csv')\n",
    "    #         display(res_final)\n",
    "\n",
    "            def convierte_str(cadena):\n",
    "                return np.array(eval(cadena.replace(' ',',').replace('\\n','').replace('nan','0')))\n",
    "\n",
    "\n",
    "            # FINAL MODEL FOR EACH OUTER WITH MEAN PARAMS\n",
    "            if arg_in.algorithm == 'mlp':\n",
    "                only_outer = res_final.query('num_seed==@num_seed').reset_index(drop=True)\n",
    "                only_outer['best_solution'] = only_outer['best_solution'].apply(lambda x: convierte_str(x))\n",
    "                only_outer['complex_best'] =  only_outer['best_solution'].apply(lambda x: x[2]).values\n",
    "                only_outer['hidden'] =  only_outer['best_solution'].apply(lambda x: x[3]).values\n",
    "                only_outer['alpha'] =  only_outer['best_solution'].apply(lambda x: 10**x[4]).values\n",
    "                only_outer['features'] =  only_outer['best_solution'].apply(lambda x: x[-len(input_names):]).values\n",
    "                mean_outer = only_outer[['VAL_RMSE_FOLD', 'VAL_MAE', 'VAL_MAPE', 'TST_RMSE_FOLD',\n",
    "                                         'TST_RMSE', 'TST_MAE', 'TST_MAPE',\n",
    "                                        'complex_best', 'hidden', 'alpha']].aggregate(['mean','std'])\n",
    "                fil0 = mean_outer.iloc[0]\n",
    "                fil0.index = ['mean_'+col for col in mean_outer.columns]\n",
    "                fil1 = mean_outer.iloc[1]\n",
    "                fil1.index = ['std_'+col for col in mean_outer.columns]\n",
    "                mean_outer = pd.concat(\n",
    "                    [only_outer[['method', 'database', 'namevar', 'size_train_val', 'size_test',\n",
    "                           'num_input_feats', 'num_seed', 'innerfold', 'run', 'model_name',\n",
    "                           'rerank_error', 'time', 'last_iter', 'mejor_val',\n",
    "                           'numindiv', 'maxiter', 'early', 'Lambda', 'c1', 'c2', 'IWmax', 'IWmin',\n",
    "                           'K', 'globthr', 'CVrep', 'CVspl', 'nruns', 'pcrossover_elitists',\n",
    "                           'pcrossover', 'best_solution']].head(1),\n",
    "                     pd.DataFrame(pd.concat([fil0,fil1])).transpose()],axis=1)\n",
    "\n",
    "                # Model with mean of hyperparameters\n",
    "                # Entrenamos con TRAIN+VAL y medimos el error con TST\n",
    "                model = MLPRegressor()\n",
    "                model.hidden_layer_sizes = int(mean_outer['mean_hidden'].values[0])\n",
    "                model.alpha = mean_outer['mean_alpha'].values[0]\n",
    "\n",
    "            if arg_in.algorithm == 'kridge':\n",
    "                only_outer = res_final.query('num_seed==@num_seed').reset_index(drop=True)\n",
    "                only_outer['best_solution'] = only_outer['best_solution'].apply(lambda x: convierte_str(x))\n",
    "                only_outer['complex_best'] =  only_outer['best_solution'].apply(lambda x: x[2]).values\n",
    "                only_outer['alpha'] =  only_outer['best_solution'].apply(lambda x: 10**x[3]).values\n",
    "                only_outer['gamma'] =  only_outer['best_solution'].apply(lambda x: 10**x[4]).values\n",
    "                only_outer['features'] =  only_outer['best_solution'].apply(lambda x: x[-len(input_names):]).values\n",
    "                mean_outer = only_outer[['VAL_RMSE_FOLD', 'VAL_MAE', 'VAL_MAPE', 'TST_RMSE_FOLD',\n",
    "                                         'TST_RMSE', 'TST_MAE', 'TST_MAPE',\n",
    "                                        'complex_best', 'alpha', 'gamma']].aggregate(['mean','std'])\n",
    "                fil0 = mean_outer.iloc[0]\n",
    "                fil0.index = ['mean_'+col for col in mean_outer.columns]\n",
    "                fil1 = mean_outer.iloc[1]\n",
    "                fil1.index = ['std_'+col for col in mean_outer.columns]\n",
    "                mean_outer = pd.concat(\n",
    "                    [only_outer[['method', 'database', 'namevar', 'size_train_val', 'size_test',\n",
    "                           'num_input_feats', 'num_seed', 'innerfold', 'run', 'model_name',\n",
    "                           'rerank_error', 'time', 'last_iter', 'mejor_val',\n",
    "                           'numindiv', 'maxiter', 'early', 'Lambda', 'c1', 'c2', 'IWmax', 'IWmin',\n",
    "                           'K', 'globthr', 'CVrep', 'CVspl', 'nruns', 'pcrossover_elitists',\n",
    "                           'pcrossover', 'best_solution']].head(1),\n",
    "                     pd.DataFrame(pd.concat([fil0,fil1])).transpose()],axis=1)\n",
    "\n",
    "                # Model with mean of hyperparameters\n",
    "                # Entrenamos con TRAIN+VAL y medimos el error con TST\n",
    "                model = res_search_model.best_model\n",
    "                model.alpha = mean_outer['mean_alpha'].values[0]\n",
    "                model.gamma = mean_outer['mean_gamma'].values[0]\n",
    "\n",
    "    #         selec_features = input_names[(np.stack(only_outer['features'].values)>0.50).mean(axis=0)>=0.50]\n",
    "            selec_features = input_names[(np.mean(np.stack(only_outer['features'].values),axis=0)>= thr_features)]\n",
    "            print(f'DB={name_db} train_val_size={train_val_size} ncols={len(input_names)} NFS={len(selec_features)}')\n",
    "            features_list_thr.append(dict(name_db=name_db,\n",
    "                                          num_seed = num_seed,\n",
    "                                          thr_features=thr_features,\n",
    "                                          num_feats=num_feats,\n",
    "                                          mean_last_iter = mean_outer['last_iter'].values[0],\n",
    "                                          num_selec = len(selec_features),\n",
    "\n",
    "                                          file_db=file_db,\n",
    "                                          results_name=results_name,\n",
    "                                          selec_features=np.array(selec_features)\n",
    "                                     ))\n",
    "\n",
    "features_list_thr = pd.DataFrame(features_list_thr)\n",
    "features_list_thr.groupby(['name_db','thr_features']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1176d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T14:50:39.888241Z",
     "start_time": "2023-04-17T14:50:39.843419Z"
    }
   },
   "outputs": [],
   "source": [
    "features_list_thr_mean = features_list_thr.groupby(['name_db','thr_features']).mean().reset_index()\n",
    "features_list_thr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fc5e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T14:53:36.628292Z",
     "start_time": "2023-04-17T14:53:36.600876Z"
    }
   },
   "outputs": [],
   "source": [
    "features_list_thr_mean.query('thr_features==@thr_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba132f2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T14:54:48.936840Z",
     "start_time": "2023-04-17T14:54:48.851504Z"
    }
   },
   "outputs": [],
   "source": [
    "for thr_features in [0.00, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70]:\n",
    "    res_total = pd.read_csv(f'res_bayes_after_pso_thrfeats_{thr_features}.csv')\n",
    "    mean_res = res_total.groupby('name_db').mean().reset_index()\n",
    "    if thr_features == 0.00:\n",
    "        db_mean = mean_res[['name_db', 'train_val_size', 'test_size', 'ncols']]\n",
    "        db_mean.rename({'OUTER_RMSE':'RMSE_0.0'}, inplace=True)\n",
    "        db_mean['last_iter'] = features_list_thr_mean.query('thr_features==@thr_features')['mean_last_iter'].values\n",
    "    db_mean[f'RMSE_{thr_features}'] = mean_res['OUTER_RMSE']\n",
    "    db_mean[f'NFs_{thr_features}'] = features_list_thr_mean.query('thr_features==@thr_features')['num_selec'].values\n",
    "db_mean                   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355e9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T14:55:24.606731Z",
     "start_time": "2023-04-17T14:55:24.557027Z"
    }
   },
   "outputs": [],
   "source": [
    "print(db_mean.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06517a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e72f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T16:45:33.923784Z",
     "start_time": "2023-04-17T16:45:33.886695Z"
    }
   },
   "outputs": [],
   "source": [
    "features_list_thr_std = features_list_thr.groupby(['name_db','thr_features']).std().reset_index()\n",
    "features_list_thr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf9d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T16:46:19.855239Z",
     "start_time": "2023-04-17T16:46:19.770520Z"
    }
   },
   "outputs": [],
   "source": [
    "for thr_features in [0.00, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70]:\n",
    "    res_total = pd.read_csv(f'res_bayes_after_pso_thrfeats_{thr_features}.csv')\n",
    "    std_res = res_total.groupby('name_db').std().reset_index()\n",
    "    if thr_features == 0.00:\n",
    "        db_std = std_res[['name_db', 'train_val_size', 'test_size', 'ncols']]\n",
    "        db_std.rename({'OUTER_RMSE':'RMSE_0.0'}, inplace=True)\n",
    "        db_std['last_iter'] = features_list_thr_std.query('thr_features==@thr_features')['mean_last_iter'].values\n",
    "    db_std[f'RMSE_{thr_features}'] = std_res['OUTER_RMSE']\n",
    "    db_std[f'NFs_{thr_features}'] = features_list_thr_std.query('thr_features==@thr_features')['num_selec'].values\n",
    "db_std                   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ab948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T16:48:19.888168Z",
     "start_time": "2023-04-17T16:48:19.867216Z"
    }
   },
   "outputs": [],
   "source": [
    "db_std[['name_db', 'RMSE_0.5', 'NFs_0.5']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
